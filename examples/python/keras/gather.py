from flexflow.keras.layers import Dense, Input, Reshape
from flexflow.keras.backend.internal import gather
from flexflow.keras.backend import sum
import flexflow.keras.optimizers
from flexflow.core import FFConfig

import numpy as np

    # idxt = torch.tensor(idx).reshape(1,-1,1).repeat(x.shape[0], 1, x.shape[-1])
    # return torch.gather(x, 1, idxt).reshape(x.shape[0], *idx.shape, -1)

def get_modified_idx(idx, hidden_shape):
    return idx.reshape(-1,1).repeat(hidden_shape, 1)

# def gather(x, idx, axis):
#     idxt = torch.tensor(idx).reshape(1,-1,1).repeat(x.shape[0], 1, x.shape[-1])
#     print(x.shape, idxt.shape, torch.gather(x, 1, idxt).shape)
#     return torch.gather(x, 1, idxt).reshape(x.shape[0], *idx.shape, -1)

def gather_example():
  # input0 = Input(shape=(20,3), dtype="float32") # B,20,3
  # out = Dense(1)(input0) # B,20,1
  # # out = Reshape((20,1))(Dense(20)(Reshape((20*3,))(input0)))

  # model = flexflow.keras.models.Model([input0], out)
  # opt = flexflow.keras.optimizers.Adam(learning_rate=0.001)
  # model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])
  # print(model.summary())
  # model.fit(
  #   x = np.random.randn(300, 20, 3).astype(np.float32),
  #   y = np.random.randn(300, 20, 1).astype(np.float32),
  #   epochs = 2
  # )

  x = np.arange(7*10*3).reshape(7, 10, 3).astype('float')
  x /= x.sum()

  y = np.array([[[6.83526999e-04, 7.29095466e-04, 7.74663933e-04],
        [6.83526999e-04, 7.29095466e-04, 7.74663933e-04],
        [6.83526999e-04, 7.29095466e-04, 7.74663933e-04],
        [9.56937799e-04, 1.00250627e-03, 1.04807473e-03],
        [9.56937799e-04, 1.00250627e-03, 1.04807473e-03],
        [9.56937799e-04, 1.00250627e-03, 1.04807473e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [1.09364320e-03, 1.13921167e-03, 1.18478013e-03],
        [1.09364320e-03, 1.13921167e-03, 1.18478013e-03],
        [1.09364320e-03, 1.13921167e-03, 1.18478013e-03],
        [5.46821599e-04, 5.92390066e-04, 6.37958533e-04],
        [5.46821599e-04, 5.92390066e-04, 6.37958533e-04],
        [5.46821599e-04, 5.92390066e-04, 6.37958533e-04],
        [0.00000000e+00, 4.55684666e-05, 9.11369332e-05],
        [0.00000000e+00, 4.55684666e-05, 9.11369332e-05],
        [0.00000000e+00, 4.55684666e-05, 9.11369332e-05]],

       [[2.05058100e-03, 2.09614946e-03, 2.14171793e-03],
        [2.05058100e-03, 2.09614946e-03, 2.14171793e-03],
        [2.05058100e-03, 2.09614946e-03, 2.14171793e-03],
        [2.32399180e-03, 2.36956026e-03, 2.41512873e-03],
        [2.32399180e-03, 2.36956026e-03, 2.41512873e-03],
        [2.32399180e-03, 2.36956026e-03, 2.41512873e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [2.46069720e-03, 2.50626566e-03, 2.55183413e-03],
        [2.46069720e-03, 2.50626566e-03, 2.55183413e-03],
        [2.46069720e-03, 2.50626566e-03, 2.55183413e-03],
        [1.91387560e-03, 1.95944406e-03, 2.00501253e-03],
        [1.91387560e-03, 1.95944406e-03, 2.00501253e-03],
        [1.91387560e-03, 1.95944406e-03, 2.00501253e-03],
        [1.36705400e-03, 1.41262247e-03, 1.45819093e-03],
        [1.36705400e-03, 1.41262247e-03, 1.45819093e-03],
        [1.36705400e-03, 1.41262247e-03, 1.45819093e-03]],

       [[3.41763500e-03, 3.46320346e-03, 3.50877193e-03],
        [3.41763500e-03, 3.46320346e-03, 3.50877193e-03],
        [3.41763500e-03, 3.46320346e-03, 3.50877193e-03],
        [3.69104580e-03, 3.73661426e-03, 3.78218273e-03],
        [3.69104580e-03, 3.73661426e-03, 3.78218273e-03],
        [3.69104580e-03, 3.73661426e-03, 3.78218273e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [3.82775120e-03, 3.87331966e-03, 3.91888813e-03],
        [3.82775120e-03, 3.87331966e-03, 3.91888813e-03],
        [3.82775120e-03, 3.87331966e-03, 3.91888813e-03],
        [3.28092960e-03, 3.32649806e-03, 3.37206653e-03],
        [3.28092960e-03, 3.32649806e-03, 3.37206653e-03],
        [3.28092960e-03, 3.32649806e-03, 3.37206653e-03],
        [2.73410800e-03, 2.77967646e-03, 2.82524493e-03],
        [2.73410800e-03, 2.77967646e-03, 2.82524493e-03],
        [2.73410800e-03, 2.77967646e-03, 2.82524493e-03]],

       [[4.78468900e-03, 4.83025746e-03, 4.87582593e-03],
        [4.78468900e-03, 4.83025746e-03, 4.87582593e-03],
        [4.78468900e-03, 4.83025746e-03, 4.87582593e-03],
        [5.05809979e-03, 5.10366826e-03, 5.14923673e-03],
        [5.05809979e-03, 5.10366826e-03, 5.14923673e-03],
        [5.05809979e-03, 5.10366826e-03, 5.14923673e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [5.19480519e-03, 5.24037366e-03, 5.28594213e-03],
        [5.19480519e-03, 5.24037366e-03, 5.28594213e-03],
        [5.19480519e-03, 5.24037366e-03, 5.28594213e-03],
        [4.64798360e-03, 4.69355206e-03, 4.73912053e-03],
        [4.64798360e-03, 4.69355206e-03, 4.73912053e-03],
        [4.64798360e-03, 4.69355206e-03, 4.73912053e-03],
        [4.10116200e-03, 4.14673046e-03, 4.19229893e-03],
        [4.10116200e-03, 4.14673046e-03, 4.19229893e-03],
        [4.10116200e-03, 4.14673046e-03, 4.19229893e-03]],

       [[6.15174299e-03, 6.19731146e-03, 6.24287993e-03],
        [6.15174299e-03, 6.19731146e-03, 6.24287993e-03],
        [6.15174299e-03, 6.19731146e-03, 6.24287993e-03],
        [6.42515379e-03, 6.47072226e-03, 6.51629073e-03],
        [6.42515379e-03, 6.47072226e-03, 6.51629073e-03],
        [6.42515379e-03, 6.47072226e-03, 6.51629073e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [6.56185919e-03, 6.60742766e-03, 6.65299613e-03],
        [6.56185919e-03, 6.60742766e-03, 6.65299613e-03],
        [6.56185919e-03, 6.60742766e-03, 6.65299613e-03],
        [6.01503759e-03, 6.06060606e-03, 6.10617453e-03],
        [6.01503759e-03, 6.06060606e-03, 6.10617453e-03],
        [6.01503759e-03, 6.06060606e-03, 6.10617453e-03],
        [5.46821599e-03, 5.51378446e-03, 5.55935293e-03],
        [5.46821599e-03, 5.51378446e-03, 5.55935293e-03],
        [5.46821599e-03, 5.51378446e-03, 5.55935293e-03]],

       [[7.51879699e-03, 7.56436546e-03, 7.60993393e-03],
        [7.51879699e-03, 7.56436546e-03, 7.60993393e-03],
        [7.51879699e-03, 7.56436546e-03, 7.60993393e-03],
        [7.79220779e-03, 7.83777626e-03, 7.88334473e-03],
        [7.79220779e-03, 7.83777626e-03, 7.88334473e-03],
        [7.79220779e-03, 7.83777626e-03, 7.88334473e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [7.92891319e-03, 7.97448166e-03, 8.02005013e-03],
        [7.92891319e-03, 7.97448166e-03, 8.02005013e-03],
        [7.92891319e-03, 7.97448166e-03, 8.02005013e-03],
        [7.38209159e-03, 7.42766006e-03, 7.47322853e-03],
        [7.38209159e-03, 7.42766006e-03, 7.47322853e-03],
        [7.38209159e-03, 7.42766006e-03, 7.47322853e-03],
        [6.83526999e-03, 6.88083846e-03, 6.92640693e-03],
        [6.83526999e-03, 6.88083846e-03, 6.92640693e-03],
        [6.83526999e-03, 6.88083846e-03, 6.92640693e-03]],

       [[8.88585099e-03, 8.93141946e-03, 8.97698792e-03],
        [8.88585099e-03, 8.93141946e-03, 8.97698792e-03],
        [8.88585099e-03, 8.93141946e-03, 8.97698792e-03],
        [9.15926179e-03, 9.20483026e-03, 9.25039872e-03],
        [9.15926179e-03, 9.20483026e-03, 9.25039872e-03],
        [9.15926179e-03, 9.20483026e-03, 9.25039872e-03],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
        [9.29596719e-03, 9.34153566e-03, 9.38710412e-03],
        [9.29596719e-03, 9.34153566e-03, 9.38710412e-03],
        [9.29596719e-03, 9.34153566e-03, 9.38710412e-03],
        [8.74914559e-03, 8.79471406e-03, 8.84028252e-03],
        [8.74914559e-03, 8.79471406e-03, 8.84028252e-03],
        [8.74914559e-03, 8.79471406e-03, 8.84028252e-03],
        [8.20232399e-03, 8.24789246e-03, 8.29346093e-03],
        [8.20232399e-03, 8.24789246e-03, 8.29346093e-03],
        [8.20232399e-03, 8.24789246e-03, 8.29346093e-03]]])


  idx = np.array([[5,2,3],[1,4,0]])
  idx = idx.reshape(-1, 1).repeat(3, -1)  # 6,3
  idx = get_modified_idx(idx, 3)

  input0 = Input(shape=(10,3,), dtype="float32")
  input1 = Input(shape=idx.shape, dtype="int32")

  out = gather(input0, input1, axis=1) # B,18,3

  model = flexflow.keras.models.Model([input0, input1], out)
  print(model.summary())

  opt = flexflow.keras.optimizers.Adam(learning_rate=0.001)
  model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])
  print(model.summary())
  model.fit(
    x = [
      x.astype(np.float32),
      idx[None, ...].repeat(7, 0).astype(np.int32)
    ],
    y = y.astype(np.float32),
    epochs = 60000
  )

  # l.get_weights(model.ffmodel)


  # input0 = Input(shape=(6,3,), dtype="float32") # B,6,3
  # out = Reshape((64*6,3), full_target_shape=True)(input0)
  # out = Dense(2, use_bias=True)(out) # B,6,2
  # out = Reshape((64,6,2), full_target_shape=True)(out)

  # model = flexflow.keras.models.Model(input0, out)
  # print(model.summary())

  # opt = flexflow.keras.optimizers.Adam(learning_rate=0.001)
  # model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])
  # print(model.summary())
  # model.fit(
  #   x = np.random.randn(300, 6, 3).astype(np.float32),
  #   y = np.random.randn(300, 6, 2).astype(np.float32),
  #   epochs = 2
  # )


if __name__ == '__main__':
    gather_example()




# x = Dense(5)(x) + y # y-> keras Tensor

# model.compile()

# y.ffhandle..set_tensor([0,0,0,0,0])