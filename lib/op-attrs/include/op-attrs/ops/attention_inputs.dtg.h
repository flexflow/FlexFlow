// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!
// If you would like to modify this datatype, instead modify
// lib/op-attrs/include/op-attrs/ops/attention_inputs.struct.toml
/* proj-data
{
  "generated_from": "700f5fb734284b7feabbdd4cb61f3183"
}
*/

#ifndef _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_INPUTS_DTG_H
#define _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_INPUTS_DTG_H

#include "fmt/format.h"
#include "nlohmann/json.hpp"
#include "op-attrs/tensor_shape.h"
#include <functional>
#include <ostream>
#include <tuple>

namespace FlexFlow {
struct MultiHeadAttentionInputs {
  MultiHeadAttentionInputs() = delete;
  MultiHeadAttentionInputs(::FlexFlow::TensorShape const &query,
                           ::FlexFlow::TensorShape const &key,
                           ::FlexFlow::TensorShape const &value);

  bool operator==(MultiHeadAttentionInputs const &) const;
  bool operator!=(MultiHeadAttentionInputs const &) const;
  bool operator<(MultiHeadAttentionInputs const &) const;
  bool operator>(MultiHeadAttentionInputs const &) const;
  bool operator<=(MultiHeadAttentionInputs const &) const;
  bool operator>=(MultiHeadAttentionInputs const &) const;
  ::FlexFlow::TensorShape query;
  ::FlexFlow::TensorShape key;
  ::FlexFlow::TensorShape value;
};
} // namespace FlexFlow

namespace std {
template <>
struct hash<FlexFlow::MultiHeadAttentionInputs> {
  size_t operator()(FlexFlow::MultiHeadAttentionInputs const &) const;
};
} // namespace std

namespace nlohmann {
template <>
struct adl_serializer<FlexFlow::MultiHeadAttentionInputs> {
  static FlexFlow::MultiHeadAttentionInputs from_json(json const &);
  static void to_json(json &, FlexFlow::MultiHeadAttentionInputs const &);
};
} // namespace nlohmann

namespace FlexFlow {
std::string format_as(MultiHeadAttentionInputs const &);
std::ostream &operator<<(std::ostream &, MultiHeadAttentionInputs const &);
} // namespace FlexFlow

#endif // _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_INPUTS_DTG_H
