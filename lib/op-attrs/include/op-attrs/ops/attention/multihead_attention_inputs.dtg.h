// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!
// If you would like to modify this datatype, instead modify
// lib/op-attrs/include/op-attrs/ops/attention/multihead_attention_inputs.struct.toml
/* proj-data
{
  "generated_from": "c57a9d1d2822a726ee9d9369d22e8e72"
}
*/

#ifndef _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_MULTIHEAD_ATTENTION_INPUTS_DTG_H
#define _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_MULTIHEAD_ATTENTION_INPUTS_DTG_H

#include "fmt/format.h"
#include "nlohmann/json.hpp"
#include "op-attrs/datatype.dtg.h"
#include "rapidcheck.h"
#include <cstddef>
#include <functional>
#include <ostream>
#include <tuple>

namespace FlexFlow {
struct MultiHeadAttentionInputs {
  MultiHeadAttentionInputs() = delete;
  explicit MultiHeadAttentionInputs(size_t const &batch_size,
                                    size_t const &sequence_length,
                                    size_t const &query_size,
                                    size_t const &key_size,
                                    size_t const &value_size,
                                    ::FlexFlow::DataType const &datatype);

  bool operator==(MultiHeadAttentionInputs const &) const;
  bool operator!=(MultiHeadAttentionInputs const &) const;
  bool operator<(MultiHeadAttentionInputs const &) const;
  bool operator>(MultiHeadAttentionInputs const &) const;
  bool operator<=(MultiHeadAttentionInputs const &) const;
  bool operator>=(MultiHeadAttentionInputs const &) const;
  size_t batch_size;
  size_t sequence_length;
  size_t query_size;
  size_t key_size;
  size_t value_size;
  ::FlexFlow::DataType datatype;
};
} // namespace FlexFlow

namespace std {
template <>
struct hash<::FlexFlow::MultiHeadAttentionInputs> {
  size_t operator()(::FlexFlow::MultiHeadAttentionInputs const &) const;
};
} // namespace std

namespace nlohmann {
template <>
struct adl_serializer<::FlexFlow::MultiHeadAttentionInputs> {
  static ::FlexFlow::MultiHeadAttentionInputs from_json(json const &);
  static void to_json(json &, ::FlexFlow::MultiHeadAttentionInputs const &);
};
} // namespace nlohmann

namespace rc {
template <>
struct Arbitrary<::FlexFlow::MultiHeadAttentionInputs> {
  static Gen<::FlexFlow::MultiHeadAttentionInputs> arbitrary();
};
} // namespace rc

namespace FlexFlow {
std::string format_as(MultiHeadAttentionInputs const &);
std::ostream &operator<<(std::ostream &, MultiHeadAttentionInputs const &);
} // namespace FlexFlow

#endif // _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_ATTENTION_MULTIHEAD_ATTENTION_INPUTS_DTG_H
