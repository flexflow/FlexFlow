// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!
// If you would like to modify this datatype, instead modify
// lib/op-attrs/include/op-attrs/ops/parallel_attention_inputs.struct.toml
/* proj-data
{
  "generated_from": "b76a39763275090d8376e1c27668d2cb"
}
*/

#ifndef _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_PARALLEL_ATTENTION_INPUTS_DTG_H
#define _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_PARALLEL_ATTENTION_INPUTS_DTG_H

#include "fmt/format.h"
#include "nlohmann/json.hpp"
#include "op-attrs/parallel_tensor_shape.h"
#include "rapidcheck.h"
#include <functional>
#include <ostream>
#include <tuple>

namespace FlexFlow {
struct ParallelMultiHeadAttentionInputs {
  ParallelMultiHeadAttentionInputs() = delete;
  ParallelMultiHeadAttentionInputs(
      ::FlexFlow::ParallelTensorShape const &query,
      ::FlexFlow::ParallelTensorShape const &key,
      ::FlexFlow::ParallelTensorShape const &value);

  bool operator==(ParallelMultiHeadAttentionInputs const &) const;
  bool operator!=(ParallelMultiHeadAttentionInputs const &) const;
  ::FlexFlow::ParallelTensorShape query;
  ::FlexFlow::ParallelTensorShape key;
  ::FlexFlow::ParallelTensorShape value;
};
} // namespace FlexFlow

namespace std {
template <>
struct hash<FlexFlow::ParallelMultiHeadAttentionInputs> {
  size_t operator()(FlexFlow::ParallelMultiHeadAttentionInputs const &) const;
};
} // namespace std

namespace nlohmann {
template <>
struct adl_serializer<FlexFlow::ParallelMultiHeadAttentionInputs> {
  static FlexFlow::ParallelMultiHeadAttentionInputs from_json(json const &);
  static void to_json(json &,
                      FlexFlow::ParallelMultiHeadAttentionInputs const &);
};
} // namespace nlohmann

namespace rc {
template <>
struct Arbitrary<FlexFlow::ParallelMultiHeadAttentionInputs> {
  static Gen<FlexFlow::ParallelMultiHeadAttentionInputs> arbitrary();
};
} // namespace rc

namespace FlexFlow {
std::string format_as(ParallelMultiHeadAttentionInputs const &);
std::ostream &operator<<(std::ostream &,
                         ParallelMultiHeadAttentionInputs const &);
} // namespace FlexFlow

#endif // _FLEXFLOW_LIB_OP_ATTRS_INCLUDE_OP_ATTRS_OPS_PARALLEL_ATTENTION_INPUTS_DTG_H
