// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!
// If you would like to modify this datatype, instead modify
// lib/op-attrs/include/op-attrs/ops/attention_inputs.struct.toml

#include "op-attrs/ops/attention_inputs.h"

namespace FlexFlow {
MultiHeadAttentionInputs::MultiHeadAttentionInputs(
    ::FlexFlow::TensorShape const &query,
    ::FlexFlow::TensorShape const &key,
    ::FlexFlow::TensorShape const &value)
    : query(query), key(key), value(value) {}
bool MultiHeadAttentionInputs::operator==(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) ==
         std::tie(other.query, other.key, other.value);
}
bool MultiHeadAttentionInputs::operator!=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) !=
         std::tie(other.query, other.key, other.value);
}
bool MultiHeadAttentionInputs::operator<(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) <
         std::tie(other.query, other.key, other.value);
}
bool MultiHeadAttentionInputs::operator>(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) >
         std::tie(other.query, other.key, other.value);
}
bool MultiHeadAttentionInputs::operator<=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) <=
         std::tie(other.query, other.key, other.value);
}
bool MultiHeadAttentionInputs::operator>=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->query, this->key, this->value) >=
         std::tie(other.query, other.key, other.value);
}
} // namespace FlexFlow

namespace std {
size_t hash<FlexFlow::MultiHeadAttentionInputs>::operator()(
    FlexFlow::MultiHeadAttentionInputs const &x) const {
  size_t result = 0;
  result ^= std::hash<::FlexFlow::TensorShape>{}(x.query) + 0x9e3779b9 +
            (result << 6) + (result >> 2);
  result ^= std::hash<::FlexFlow::TensorShape>{}(x.key) + 0x9e3779b9 +
            (result << 6) + (result >> 2);
  result ^= std::hash<::FlexFlow::TensorShape>{}(x.value) + 0x9e3779b9 +
            (result << 6) + (result >> 2);
  return result;
}
} // namespace std

namespace nlohmann {
FlexFlow::MultiHeadAttentionInputs
    adl_serializer<FlexFlow::MultiHeadAttentionInputs>::from_json(
        json const &j) {
  return {j.at("query").template get<::FlexFlow::TensorShape>(),
          j.at("key").template get<::FlexFlow::TensorShape>(),
          j.at("value").template get<::FlexFlow::TensorShape>()};
}
void adl_serializer<FlexFlow::MultiHeadAttentionInputs>::to_json(
    json &j, FlexFlow::MultiHeadAttentionInputs const &v) {
  j["__type"] = "MultiHeadAttentionInputs";
  j["query"] = v.query;
  j["key"] = v.key;
  j["value"] = v.value;
}
} // namespace nlohmann

namespace FlexFlow {
std::string format_as(MultiHeadAttentionInputs const &x) {
  std::ostringstream oss;
  oss << "<MultiHeadAttentionInputs";
  oss << " query=" << x.query;
  oss << " key=" << x.key;
  oss << " value=" << x.value;
  oss << ">";
  return oss.str();
}
std::ostream &operator<<(std::ostream &s, MultiHeadAttentionInputs const &x) {
  return s << fmt::to_string(x);
}
} // namespace FlexFlow
