// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!
// If you would like to modify this datatype, instead modify
// lib/op-attrs/include/op-attrs/ops/attention/multihead_attention_inputs.struct.toml
/* proj-data
{
  "generated_from": "c57a9d1d2822a726ee9d9369d22e8e72"
}
*/

#include "op-attrs/ops/attention/multihead_attention_inputs.dtg.h"

#include "op-attrs/datatype.dtg.h"
#include <cstddef>
#include <sstream>

namespace FlexFlow {
MultiHeadAttentionInputs::MultiHeadAttentionInputs(
    size_t const &batch_size,
    size_t const &sequence_length,
    size_t const &query_size,
    size_t const &key_size,
    size_t const &value_size,
    ::FlexFlow::DataType const &datatype)
    : batch_size(batch_size), sequence_length(sequence_length),
      query_size(query_size), key_size(key_size), value_size(value_size),
      datatype(datatype) {}
bool MultiHeadAttentionInputs::operator==(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) == std::tie(other.batch_size,
                                              other.sequence_length,
                                              other.query_size,
                                              other.key_size,
                                              other.value_size,
                                              other.datatype);
}
bool MultiHeadAttentionInputs::operator!=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) != std::tie(other.batch_size,
                                              other.sequence_length,
                                              other.query_size,
                                              other.key_size,
                                              other.value_size,
                                              other.datatype);
}
bool MultiHeadAttentionInputs::operator<(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) < std::tie(other.batch_size,
                                             other.sequence_length,
                                             other.query_size,
                                             other.key_size,
                                             other.value_size,
                                             other.datatype);
}
bool MultiHeadAttentionInputs::operator>(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) > std::tie(other.batch_size,
                                             other.sequence_length,
                                             other.query_size,
                                             other.key_size,
                                             other.value_size,
                                             other.datatype);
}
bool MultiHeadAttentionInputs::operator<=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) <= std::tie(other.batch_size,
                                              other.sequence_length,
                                              other.query_size,
                                              other.key_size,
                                              other.value_size,
                                              other.datatype);
}
bool MultiHeadAttentionInputs::operator>=(
    MultiHeadAttentionInputs const &other) const {
  return std::tie(this->batch_size,
                  this->sequence_length,
                  this->query_size,
                  this->key_size,
                  this->value_size,
                  this->datatype) >= std::tie(other.batch_size,
                                              other.sequence_length,
                                              other.query_size,
                                              other.key_size,
                                              other.value_size,
                                              other.datatype);
}
} // namespace FlexFlow

namespace std {
size_t hash<FlexFlow::MultiHeadAttentionInputs>::operator()(
    ::FlexFlow::MultiHeadAttentionInputs const &x) const {
  size_t result = 0;
  result ^= std::hash<size_t>{}(x.batch_size) + 0x9e3779b9 + (result << 6) +
            (result >> 2);
  result ^= std::hash<size_t>{}(x.sequence_length) + 0x9e3779b9 +
            (result << 6) + (result >> 2);
  result ^= std::hash<size_t>{}(x.query_size) + 0x9e3779b9 + (result << 6) +
            (result >> 2);
  result ^= std::hash<size_t>{}(x.key_size) + 0x9e3779b9 + (result << 6) +
            (result >> 2);
  result ^= std::hash<size_t>{}(x.value_size) + 0x9e3779b9 + (result << 6) +
            (result >> 2);
  result ^= std::hash<::FlexFlow::DataType>{}(x.datatype) + 0x9e3779b9 +
            (result << 6) + (result >> 2);
  return result;
}
} // namespace std

namespace nlohmann {
::FlexFlow::MultiHeadAttentionInputs
    adl_serializer<::FlexFlow::MultiHeadAttentionInputs>::from_json(
        json const &j) {
  return ::FlexFlow::MultiHeadAttentionInputs{
      j.at("batch_size").template get<size_t>(),
      j.at("sequence_length").template get<size_t>(),
      j.at("query_size").template get<size_t>(),
      j.at("key_size").template get<size_t>(),
      j.at("value_size").template get<size_t>(),
      j.at("datatype").template get<::FlexFlow::DataType>()};
}
void adl_serializer<::FlexFlow::MultiHeadAttentionInputs>::to_json(
    json &j, ::FlexFlow::MultiHeadAttentionInputs const &v) {
  j["__type"] = "MultiHeadAttentionInputs";
  j["batch_size"] = v.batch_size;
  j["sequence_length"] = v.sequence_length;
  j["query_size"] = v.query_size;
  j["key_size"] = v.key_size;
  j["value_size"] = v.value_size;
  j["datatype"] = v.datatype;
}
} // namespace nlohmann

namespace rc {
Gen<::FlexFlow::MultiHeadAttentionInputs>
    Arbitrary<::FlexFlow::MultiHeadAttentionInputs>::arbitrary() {
  return gen::construct<::FlexFlow::MultiHeadAttentionInputs>(
      gen::arbitrary<size_t>(),
      gen::arbitrary<size_t>(),
      gen::arbitrary<size_t>(),
      gen::arbitrary<size_t>(),
      gen::arbitrary<size_t>(),
      gen::arbitrary<::FlexFlow::DataType>());
}
} // namespace rc

namespace FlexFlow {
std::string format_as(MultiHeadAttentionInputs const &x) {
  std::ostringstream oss;
  oss << "<MultiHeadAttentionInputs";
  oss << " batch_size=" << x.batch_size;
  oss << " sequence_length=" << x.sequence_length;
  oss << " query_size=" << x.query_size;
  oss << " key_size=" << x.key_size;
  oss << " value_size=" << x.value_size;
  oss << " datatype=" << x.datatype;
  oss << ">";
  return oss.str();
}
std::ostream &operator<<(std::ostream &s, MultiHeadAttentionInputs const &x) {
  return s << fmt::to_string(x);
}
} // namespace FlexFlow
